<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>ECE4760 Final Project</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<script>
			window.MathJax = { tex: { inlineMath: [['\\(','\\)'], ['$', '$']] } };
		</script>
		<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<h1>Jamayne's Robot</h1>
						<p>Stephen Barlett, Jamayne Gyimah-Danquah, Md Shad<br />
						HTML Template by <a href="https://twitter.com/ajlkn">@ajlkn</a> for <a href="https://html5up.net">HTML5 UP</a>.</p>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#intro" class="active">Introduction</a></li>
							<li><a href="#hld">High Level Design</a></li>
							<li><a href="#hwdesign">Hardware Design</a></li>
							<li><a href="#swdesign">Program Design</a></li>
							<li><a href="#gesturecontrolhw">Gesture Hardware</a></li>
							<li><a href="#gesturecontrolsw">Gesture Software</a></li>
							<li><a href="#results">Results</a></li>
							<li><a href="#conclusions">Conclusions</a></li>
							<li><a href="#appendix">Appendix</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

<!-- Introduction -->
<section id="intro" class="main">
	<div class="spotlight">
	  <div class="content">
		<header class="major">
		  <h2>Introduction</h2>
		</header>
  
		<div class="intro-text">

			<!-- Project sound bite -->
			<p><strong>
			  For our ECE 4760 final project, we designed and built a two-wheeled, self-balancing robot that uses real-time feedback control
			  to remain upright while being controlled through a web interface and gesture-based input.
			</strong></p>
		  
			<p>
			 At its core, the robot behaves like an inverted
			  pendulum, so when it starts to tip, it senses the motion and drives its wheels to bring itself
			  back into balance.
			</p>
		  
			<p>
			  This project gave us the opportunity to bring together many of the ideas we learned throughout
			  ECE 4760 and apply them to a real, physical system. Much of our approach was inspired by earlier
			  labs and lecture material, especially the inverted pendulum examples discussed in class and on
			  the course website, as well as Lab 3, where we used PID control to stabilize a one-dimensional
			  helicopter. Those exercises gave us intuition for how feedback control behaves in practice and
			  directly shaped how we approached this design.
			</p>
		  
			<p>
			  The robot is controlled by a Raspberry Pi Pico W running a PID controller on the RP2040
			  microcontroller. Using data from an onboard IMU, the controller continuously estimates the
			  robot’s tilt angle and how fast that angle is changing. We combine accelerometer and gyroscope
			  measurements using a complementary filter, another technique we learned in class, to produce a
			  stable and responsive angle estimate. Based on this information, the controller computes motor
			  commands at a high rate to keep the robot balanced.
			</p>
		  
			<p>
			  We also wanted the robot to be interactive rather than just balancing in place. To achieve this,
			  we built a web-based interface hosted directly on the Pico W that allows us to monitor the system
			  and adjust parameters in real time. In addition, we implemented gesture-based control so a user
			  can command the robot to move forward or backward based on the tilt of a handheld device.
			</p>
		  
			<p>
			  Throughout the project, we went through several design iterations. Decisions about robot height,
			  weight distribution, motor placement, and chassis layout all had noticeable effects on control
			  performance, and testing often forced us to revisit earlier choices. The final robot reflects
			  this iterative process and captures what we think ECE 4760 is really about: combining theory,
			  hardware, and software to build something that actually works in the real world.
			</p>
		  
		  </div>
		  
  
		<ul class="actions">
		  <li>
			<a href="https://youtu.be/V_mZqi3zYsA" class="button">Demo Video</a>
		  </li>
		</ul>
	  </div>
  
	  <span class="image">
		<img src="images/cartoon-bot.png" alt="cartoon-bot" />
	  </span>
	</div>
  </section>
  
	
  							<section id="hld" class="main">
								<div class="spotlight">
								  <div class="content">
									<header class="major">
									  <h2>High Level Design</h2>
									</header>
									<h3>Project Rationale and Inspiration</h3>

									<p>
									  The idea for this project came directly from concepts and demonstrations covered throughout
									  ECE 4760, particularly the inverted pendulum systems discussed in lecture and previous laboratory
									  exercises. We were interested in building a system that was both mechanically challenging and
									  control-intensive, where small design decisions would have visible effects on system behavior.
									</p>
									
									<p>
									  In particular, we drew inspiration from earlier inverted pendulum examples presented in class
									  and on the course website, as well as from Lab 3, where we implemented PID control to stabilize a
									  one-dimensional helicopter. That lab helped build intuition for how real-world feedback systems
									  behave, including the effects of noise, delays, and imperfect actuation. This project allowed us
									  to extend those ideas into a fully physical, dynamically unstable system.
									</p>
							<p>
							  Our high-level design process began with creating a full 3-D CAD model in Onshape. As a team,
							  we wanted to fully think through the mechanical structure of the robot before building anything
							  physically. Modeling the robot in CAD allowed us to reason about dimensions, material choices,
							  weight distribution, and how all of the subsystems would fit together. This step helped us catch
							  several potential issues early, particularly related to motor placement, center of mass, and
							  wiring, before committing to fabrication.
							</p>
						  
							<p>
							  Rather than treating the CAD model as a static drawing, we used it as an iterative design tool.
							  As our understanding of the physics and control requirements improved, we repeatedly revisited
							  the model and adjusted the design to better align with our goals for stability, symmetry, and
							  ease of assembly.
							</p>

							<figure style="text-align: center;">
								<img src="images/robotassembly.png" alt="robot-assembly" style="max-width: 50%; height: auto;" />

								<figcaption>
									Full 3D CAD assembly of the robot, showing overall structure, motor placement, wheel geometry,
									and relative positioning of major subsystems.
									</figcaption>							</figure>
							
							<ul class="actions">
								<li>
								  <a href="https://cad.onshape.com/documents/d4ea7420d6f71259f6b142d5/w/6c7774b5557b06e9d49a10a8/e/8654f4ecfb2beb2b67ef4a9b?renderMode=0&uiState=6945dca5a52915c73c799366"
									 class="button"
									 target="_blank">
									View Full CAD Model (Onshape)
								  </a>
								</li>
							  </ul>
						  
			
							  <h3>Background Math and Physical Model</h3>

<p>
  At a high level, our robot can be modeled as an inverted pendulum mounted on a pair of driven
  wheels. When the robot tilts away from the upright position, gravity produces a torque about the
  wheel axle that causes the system to fall further unless corrective action is taken.
</p>

<p>
  The controller’s goal is to generate wheel acceleration that counteracts this gravitational
  torque. This relationship depends on several physical parameters, including the mass of the
  robot, the height of the center of mass, and the wheel radius. These relationships guided our
  mechanical design decisions and informed our motor selection, wheel size, and chassis height.
</p>

<p>
  The control problem is inherently dynamic and time-dependent, which motivated the use of PID
  control. The proportional term responds to instantaneous tilt error, the integral term corrects
  steady-state bias, and the derivative term provides damping based on angular velocity. These
  concepts directly build on material covered in lecture and earlier labs.
</p>
							<h3>Motor Torque and Weight Constraints</h3>
						  
							<p>
							  One of the first constraints we considered was whether our motors could realistically support
							  the weight of the robot while still providing enough torque for balance corrections. We selected
							  48:1 DC gear motors rated at a maximum output torque of 0.078 N·m and paired them with wheels
							  of radius 5 cm (0.05 m).
							</p>
						  
							<p>
							  To understand what this meant in practice, we related motor torque to the force applied at the
							  wheel–ground interface using the standard torque relationship:
							</p>
						  
							<figure style="text-align: center;">
							  <p>\( \tau = F r \)</p>
							  <p>\( F = \frac{\tau}{r} \)</p>
							  <p>\( F_{\text{motor}} = \frac{0.078}{0.05} = 1.56 \text{ N} \)</p>
							  Figure 3: Relationship between motor torque and the horizontal force applied at the wheel–ground interface.
							</figure>
						  
							<p>
								<figcaption>
									Relationship between motor torque and the horizontal force applied at the wheel–ground interface.
								</figcaption>						
								</p>
						  
							<figure style="text-align: center;">
							  <p>\( F_{\text{total}} = 2 \times 1.56 = 3.12 \text{ N} \)</p>
							  <figcaption>
								Total horizontal force available from both motors acting together.
								</figcaption>							
							</figure>
						  
							<p>
							  The completed robot had a total mass of approximately 3 lb (1.36 kg), corresponding to a
							  gravitational force of:
							</p>
						  
							<figure style="text-align: center;">
							  <p>\( F_g = mg = (1.36)(9.81) \approx 13.3 \text{ N} \)</p>
							  <figcaption>
								Gravitational force acting on the robot due to its total mass.
								</figcaption>							
							</figure>
						  
							<p>
							  At first glance, this might suggest that the motors are insufficient; however, a self-balancing
							  robot does not require the motors to lift the robot vertically. Instead, the motors generate
							  horizontal acceleration of the wheels to correct angular deviations of the inverted pendulum
							  system. Only a fraction of the robot’s weight contributes to the required corrective torque at
							  small tilt angles.
							</p>
						  
							<p>
							  This understanding guided our design decisions and gave us confidence that, with appropriate
							  height selection and PID control, our motors would be capable of stabilizing a 3 lb robot. This
							  was ultimately confirmed through experimental testing.
							</p>
							<h3>Logical System Structure</h3>

							<p>
							  From a system-level perspective, the robot is organized as a closed-loop feedback system. Sensor
							  data from the IMU is continuously sampled and filtered to estimate the robot’s orientation. This
							  estimate is passed to the PID controller, which computes a corrective control signal. That signal
							  is then translated into PWM commands that drive the motors, completing the feedback loop.
							</p>
							
							<p>
							  This logical structure influenced both the hardware and software design. Mechanically, we aimed
							  to create a symmetric, predictable platform so that the control assumptions would hold. In
							  software, we prioritized deterministic timing and consistent sampling rates to ensure stable
							  controller behavior.
							</p>
							<h3>Effect of Robot Height on Stability</h3>
						  
							<p>
							  With motor limitations in mind, we spent significant time discussing how tall the robot should
							  be. Height plays a major role in the dynamics of a self-balancing robot because it determines
							  the location of the center of mass.
							</p>
						  
							<p>
							  If the robot is too tall, the center of mass is higher, which increases the gravitational torque
							  during tilt and demands larger corrective torques from the motors. If the robot is too short,
							  the center of mass lies close to the wheel axle, reducing the gravitational restoring torque and
							  making the system more sensitive to noise, disturbances, and control latency.
							</p>
						  
							<p>
							  We ultimately chose a moderate height that struck a balance between these two extremes. This
							  provided a measurable tilt response for the controller while remaining within the torque
							  capabilities of our motors.
							</p>
						  
							<h3>CAD Iterations and Motor Orientation</h3>
						  
							<p>
							  During CAD development, we explored several motor mounting configurations. One issue we noticed
							  early was that the motor shafts were slightly offset within the motor housings rather than being
							  centered.
							</p>
						  
							<p>
							  One idea we considered was mounting the motors horizontally but in opposite orientations so that
							  the shaft offsets would cancel each other out. While this approach was theoretically sound, it
							  added mechanical complexity and made precise alignment more difficult.
							</p>
						  
							<p>
							  We ultimately decided to mount the motors vertically, which ensured symmetry about the center
							  of the robot and simplified both the mechanical assembly and mass distribution. This decision
							  required us to revise our initial CAD design, but it resulted in a cleaner and more predictable
							  structure.
							</p>
						  
							<h3>Chassis Design and Fabrication</h3>
						  
							<p>
							  For the overall chassis, we chose to use clear acrylic (plexiglass). The final mechanical
							  assembly consists of three main acrylic plates forming the body of the robot, six acrylic
							  interconnect pieces used to attach the motors, four M5 threaded rods, twenty-four M5 nuts,
							  and plastic adhesive for rigid bonding.
							</p>
						  
							<p>
							  Clear acrylic was chosen primarily because it allowed us to easily see internal components
							  during assembly and testing. This was especially useful during debugging, as we frequently
							  needed to inspect wiring, motor drivers, and power connections without disassembling the robot.
							  Additionally, acrylic can be precisely fabricated using a laser cutter, allowing us to quickly
							  iterate on our design.
							</p>
						  
							<p>
							  DXF files exported from our Onshape CAD model were submitted to the Rapid Prototyping Lab for
							  laser cutting. The design intentionally includes slits and openings in the three main plates
							  to allow wires from the motor circuit, IMU, and battery pack to pass cleanly between layers.
							</p>
						
						  
							<figure style="text-align: center;">
								<img src="images/mainframefirst.png" alt="main-frame" style="max-width: 50%; height: auto;" />
								<figcaption>
									DXF design of the main structural frame used to mount the motors and wheels.
									</figcaption>							
								</figure>
						  
							<figure style="text-align: center;">
								<img src="images/mainframetwo.png" alt="support-frame" style="max-width: 50%; height: auto;" />

								<figcaption>
									DXF design of the supporting frame used to mount the motor driver circuit, IMU, and battery pack.
									</figcaption>
																
								</figure>
						  
							<figure style="text-align: center;">
								<img src="images/connectorcadfinals.png" alt="connector" style="max-width: 50%; height: auto;" />

								<figcaption>
									DXF designs of the connector pieces used to attach the motors to the main chassis.
									</figcaption>
																
								</figure>
							<h3>Hardware and Software Tradeoffs</h3>

							<p>
							  Many of our design decisions involved tradeoffs between hardware simplicity and software
							  complexity. For example, achieving perfect mechanical symmetry is difficult in practice, so we
							  relied on software compensation through PID tuning to handle small imbalances.
							</p>
							
							<p>
							  Similarly, placing heavier components higher on the robot increased the difficulty of mechanical
							  stabilization but improved controllability by making tilt errors more pronounced. Rather than
							  minimizing height purely for stability, we chose a configuration that gave the controller better
							  authority, accepting the need for careful tuning in software.
							</p>
							
							<p>
							  On the software side, we prioritized real-time performance and responsiveness over feature
							  complexity. Running the controller at a high and consistent rate required careful use of
							  interrupts and timing, but this tradeoff resulted in significantly improved stability.
							</p>
							
<h3>Mechanical Adjustments for Tuning and Testing</h3>

<p>
  As we started tuning the PID controller, it became clear very quickly that the robot was going to
  fall a lot before it worked well. To avoid damaging the chassis or electronics during these early
  tests, we added protective foam around the edges of the robot. This gave the robot a softer
  landing when it fell and let us safely experiment with more aggressive PID gains without worrying
  about breaking anything.
</p>

<figure style="text-align: center;">
	<img src="images/foam.png" alt="foam" style="max-width: 75%; height: auto;" />

	<figcaption>
		Protective foam added around the edges of the robot to reduce impact during early PID tuning
		and testing.
		</figcaption>
</figure>

<p>
  We also spent time experimenting with where to place the heavier components on the robot.
  The battery pack, which is one of the heaviest parts, was mounted on the top level, while the IMU
  and motor driver circuit were placed on the middle level. Putting more weight higher up increased
  the height of the center of mass, which made the robot’s tilting motion more noticeable and easier
  for the controller to react to during balancing.
</p>
<figure style="text-align: center;">
	<img src="images/adjustments.png" alt="adjustments" style="max-width: 75%; height: auto;" />

	<figcaption>
		Placement of major hardware components, including the battery pack, IMU, and motor driver
		circuit, across different levels of the chassis.
		</figcaption>
		
</figure>
<p>
  In practice, mounting everything perfectly centered was harder than we expected. Small offsets
  from wiring, connectors, and mounting holes caused slight imbalances that showed up during
  testing. Even small asymmetries in weight distribution had a noticeable effect on how the robot
  behaved.
</p>

<p>
  To correct this, we made a series of small mechanical adjustments by adding extra M5 nuts and
  threaded rods to the top level of the robot. Although this slightly increased the overall weight,
  our main goal was to counteract existing weight offsets rather than add mass unnecessarily. By
  placing these additions strategically, we were able to better center the robot’s mass and improve
  balance consistency.
</p>
<figure style="text-align: center;">
	<img src="images/balancingcomponents.png" alt="balancingcomponents" style="max-width: 75%; height: auto;" />

	<figcaption>
		Additional threaded rods and nuts added to the top level to compensate for small mass
		imbalances and improve center-of-mass alignment.
		</figcaption>
		</figure>
<p>
  These adjustments reinforced how closely the mechanical design and control performance are
  connected. Many of the improvements we saw during tuning came not just from changing PID gains,
  but from making small, deliberate changes to the physical structure of the robot.
</p>

<h3>Cost of Project</h3>

<p>
  One of our design goals was to keep the overall cost of the robot relatively low while still
  achieving reliable mechanical performance and real-time control. Most components were selected
  from commonly available parts used throughout ECE 4760 labs, and several items (such as the
  microcontroller and IMU) were already provided or reused from previous coursework.
</p>

<table style="width:100%; border-collapse: collapse; margin-top: 1em;">
  <thead>
    <tr>
      <th style="border-bottom: 2px solid #ccc; text-align: left;">Component</th>
      <th style="border-bottom: 2px solid #ccc; text-align: right;">Cost (USD)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Clear acrylic plexiglass (pack)</td>
      <td style="text-align: right;">$8</td>
    </tr>
    <tr>
      <td>48:1 DC gearbox motors (2)</td>
      <td style="text-align: right;">$4</td>
    </tr>
    <tr>
      <td>M5 nuts (24)</td>
      <td style="text-align: right;">$4</td>
    </tr>
    <tr>
      <td>M5 threaded rods (4)</td>
      <td style="text-align: right;">$4</td>
    </tr>
    <tr>
      <td>Robot wheels (2)</td>
      <td style="text-align: right;">$2</td>
    </tr>
    <tr>
      <td>Plastic super glue</td>
      <td style="text-align: right;">$5</td>
    </tr>
    <tr>
      <td>Raspberry Pi Pico W</td>
      <td style="text-align: right;">$6</td>
    </tr>
    <tr>
      <td>IMU (MPU-6050)</td>
      <td style="text-align: right;">$3</td>
    </tr>
    <tr>
      <td>Batteries</td>
      <td style="text-align: right;">$5</td>
    </tr>
    <tr>
      <td>Battery holder</td>
      <td style="text-align: right;">$5</td>
    </tr>
    <tr>
      <td>Protective foam</td>
      <td style="text-align: right;">$1</td>
    </tr>
    <tr>
      <td style="border-top: 2px solid #ccc;"><strong>Total Cost</strong></td>
      <td style="border-top: 2px solid #ccc; text-align: right;"><strong>$47</strong></td>
    </tr>
  </tbody>
</table>

<p>
  Overall, the total cost of the robot was approximately <strong>$47</strong>. This demonstrates that
  a fully functional self-balancing robot with real-time control, wireless interaction, and custom
  mechanical fabrication can be built at relatively low cost using widely available components.
</p>

<h3>Intellectual Property Considerations</h3>

<p>
  This project was developed entirely for educational purposes as part of ECE 4760. While
  self-balancing robots and inverted pendulum systems are widely studied and used in commercial
  products, our implementation does not attempt to reproduce or replicate any specific patented
  design.
</p>

<p>
  The mechanical design, control algorithms, and software were developed independently by our
  team using publicly available course materials, datasheets, and academic resources. Any external
  code or concepts used were either provided as part of the course infrastructure or adapted from
  publicly available educational examples with appropriate attribution.
</p>

<p>
  To the best of our knowledge, this project does not infringe on any existing patents,
  copyrights, or trademarks and is intended solely as a demonstration of embedded systems and
  control principles.
</p>

						  
						  </section>						  
						<!-- Hardware Design -->
							<section id="hwdesign" class="main">
								<h2>Hardware Design</h2>
								<p> <!-- BODY TEXT FOR HW DESIGN -->
									<figure style="text-align: center;">
										<img src="images/full-solderboard.jpg" alt="hardware-diagram" style="max-width: 100%; height: auto;" />
										<figcaption>Figure #: Full solderboard assembly showing all components</figcaption>
									</figure>
									
									Our robot's circuit is built onto one solderboard - containing our motor circuit and Pico-W controller. The above figure 
									shows the final breadboard with labels indicating wires to off-board components (motors, imu, etc.). Below is a listing of connections
									made from the Pico-W to the rest of the circuit, as well as a circuit diagram for the motor drivers.
								</p>

								<figure style="text-align: center;">
									<div style="border:1px solid #ddd; padding: 0.5em; border-radius: 0.5em; background-color: #f9f9f9; text-align: left;">
										<ul>
											<li>Pin 3: 6 Volt COM</li>
											<li>Pin 6: 4N35-0 1 (Anode) </li>
											<li>Pin 7: 4N35-1 1 (Anode) </li>
											<li>Pin 11: MPU-6050 SDA </li>
											<li>Pin 12: MPU-6050 SCL </li>
											<li>Pin 36: MPU-6050 3.3V</li>
											<li>Pin 39: 5V (through diode)</li>
										</ul>
									</div>
									<figcaption>Figure #: Pico-W Connection Listing</figcaption>
								</figure>


								<figure style="text-align: center;">
									<img src="images/final-circuit.png" alt="hardware-diagram" style="max-width: 100%; height: auto;" />
									<figcaption>Figure #: Motor driver/H-Bridge circuit adapted for two motors.</figcaption>
								</figure>
								<p>
									Our motor circuit was adapted from the <a href="https://vanhunteradams.com/Pico/ReactionWheel/HBridgeCircuit.html">Inverted Pendulum Lab</a>
									that has been offered in previous semesters of ECE4760 with Hunter Adams. Our changes include adding a second H-Bridge to drive our second motor.
									<br>
									We have two PWM channels coming from the Pico-W (discussed in software design) that are optically isolated from our noisy motor circuit using two 4N35 optocouplers.
									One PWM signal drives input A of both L9110 H-Bridges, and the other drives input B. The L9110s that we chose were convenient because they included hardware
									safeguards that prevent shorting power to ground in the case that both inputs are high - although our software ensures that this never happens (discussed 
									later). When we enable PWM0, the H-Bridge allows IA through - sending current through our motors from IA to IB. When we enable PWM1, the H-Bridge allows IB 
									through, sending current through our motors from IB to IA. This enables forward and backwards movement, essential for keeping our bi-ped standing up.
									<br>
									Concerning power - our entire robot runs off one 6V 4-AA battery pack. Our motors are rated for 12V, but they recieved enough power from this pack to keep our
									robot upright. Running these motors at half power also allowed the batteries to last longer (lower current draw, around 550 mA including the Pico-W). To power
									the Pico-W we use one 1N diode for a small voltage drop to around 5.5V, which was safe for powering it via the VSYS pin. This diode also protected the Pico-W
									from trying to source current to the motors running off the same battery pack.
								</p>
							</section>

						<!-- Software Design -->
							<section id="swdesign" class="main">
								<h2>Software Design</h2>
								<p> <!-- BODY TEXT FOR HIGH LEVEL DESIGN -->
									The onboard software of this robot is comprised of two parallel threads of execution (using both cores on the Pico-W), as well as several <a href=https://people.ece.cornell.edu/land/courses/ece4760/PIC32/index_Protothreads.html>"protothreads"</a> responsible
									for scheduling various tasks on each core. Below is a general overview of the responsibilities of each core, as well as a listing and description of each thread running
									on that core. Note that our TCP server was adapted from a project originally by Professor Bruce Land for the RP2350 which is documented <a href="https://people.ece.cornell.edu/land/courses/ece4760/pi_pico/wifi_ap_web_server/index_access_pt_rp2350.html">here.</a>
									Our changes include developing two new web pages to display, and recieving HTTP requests from a Pico-W client. 
								</p>
								<figure style="text-align: center;">
									<div style="border:1px solid #ddd; padding: 0.5em; border-radius: 0.5em; background-color: #f9f9f9; text-align: left;">
										Core 0: Handles networking and debugging information.
										<ul>
											<li>DHCP Server (non-protothread): Initializes a DHCP server listening on Core 0 for any incoming DHCP requests and responding appropriately. </li>
											<li>DNS Server (non-protothread): Initializes a DNS server listening on Core 0 for handling DNS traffic to our mini-server. </li>
											<li>TCP Server (non-protothread): Initializes a TCP server listening on Core 0 for handling HTTP GET requests and sending replies.</li>
											<li>Serial Protothread: Thread handling printing debug information to the serial output, used extensively during development.  </li>
										</ul>
										Core 1: Handles high-precision, high-bandwidth PID calculations.
										<ul>
											<li>PID ISR: runs whenever our PWM channels wrap ( approximately every 0.83ms ) reading sensors and computing our error function.</li>
										</ul>
									</div>
									<figcaption>Figure #: Onboard Software Listing</figcaption>
								</figure>

								<h3>PID Control</h3>
								<p>
									PID control is the heart of every self balancing robot. Core 1 of our onboard Pico handles the PID. Our ISR triggers at a target speed of 1.2kHz, giving us enough time to detect and respond to the angle changes of the robot.
									Our <code>on_pwm_wrap</code> function reads raw data from our accelerometer and gyroscope, approximates the devices actual angle via a <a href="https://vanhunteradams.com/Pico/ReactionWheel/Complementary_Filters.html">complementary filter</a> (discussed later), then executes the <code>pid_step</code>
									function that handles error computation and control response. Our PID function runs at a constant rate, aligned with our angle sampling and
									PWM wrap. We use hardware interrupts to ensure that our controller executes at a consistent
									rate, since the integral and derivative components depend on a fixed time constant τ.
								</p>
								<figure style="text-align: center;">
									<p>
										\( C = \mathrm{clamp}\!\left((K_p \cdot e) + (K_i \cdot \Sigma e) + (K_d \cdot \Delta e),\ \min,\ \max\right) \)
									</p>
									<figcaption>Figure #: PID Control (C) general equation.</figcaption>
								</figure>

								<p>
									On every loop iteration, we compute the error, update our accumulated error, and sample
									the gyroscope for ∆θ. We then compute our control output according to the above equation.
									<br>
									One of the most crucial parts of our PID implementation is a symmetric range for our control value around 0. This allows our controller to produce positive and negative control values, which we can interpret as forwards/backwards drive based on the sign of the value. This logic is handled in
									<code>pid_step</code> function. This symmetric range introduced some "friction" at duty cycles in the range of roughly (-1000, 1000) that were too small to actually spin our motors. This caused increased wind-up time and slower responses overall. We overcame this by applying a +1000 unit offset
									to our duty cycle as we set the PWM Channel output, then capping the PID at our maximum duty cycle minus 1000 (in our case, 4000). This clamps our duty cycle outside of this range, significantly increasing reaction speeds.
									<br>
									Another obstacle that we encountered with our dual-motor setup was differences in the reaction properties of our motors when rotating them forwards versus backwards. We found that one direction was considerably less reactive, causing our robot to favor falling towards that side even when optimally tuned.
									We resolved this issue by running a secondary P,I, and D calculation with smaller gains that could be used to offset the output duty cycle for the less favorable direction. This worked well, and resulted in us achieving the stability demonstrated in our demo video.
								</p>

								<h3>Complementary Filter</h3>
								<p>
									We utilize a complementary filter to estimate the robot's orientation using both acelerometer and gyroscope data. The gyroscope produces a clean signal that measures the
									rate of change in orientation but accumulates drift over time. The accelerometer measures
									the absolute orientation relative to Earth’s gravity but introduces substantial high-frequency
									noise.
									To combine the strengths of both sensors, we high-pass filter the gyroscope data (removing long-term drift) and low-pass filter the accelerometer data (removing high-frequency
									noise). The resulting estimate provides both accuracy and responsiveness.
									This is implemented by weighting the gyroscope estimate heavily (0.999) and the accelerometer estimate lightly (0.001):
								</p>

								<figure style="text-align: center;">
									<p>
										\( \theta_{\text{filtered}} =
										0.999\,(\theta_{\text{prev}} + \Delta\theta_{\text{gyro}})
										+ 0.001\,(\theta_{\text{accel}}) \)
									</p>
									<figcaption>Figure #: Complementary Filter general equation.</figcaption>
								</figure>

								<p>
									The below block diagram illustrates the actual filtering process, including all inputs and outputs to the filter.
								</p>

								<figure style="text-align: center;">
									<img src="images/complementary_filter.png" alt="complementary-filter" style="max-width: 100%; height: auto;" />
									<figcaption>Figure #: Block diagram for the complementary filter implemented by our program. From <a href="https://vanhunteradams.com/Pico/ReactionWheel/Complementary_Filters.html">Adams, Complementary Filters</a> </figcaption>
								</figure>

							</section>
						
							<!-- Gesture Control Hardware -->
							<section id="gesturecontrolhw" class="main">
								  <h2>Gesture Hardware Configuration</h2>

								<p>
									The gesture input device is implemented on a breadboard using a
									<strong>Raspberry Pi Pico W</strong> and an <strong>MPU6050 Inertial Measurement Unit (IMU)</strong>.
									The Pico W serves as both the sensing and processing unit, while the MPU6050
									provides 3-axis accelerometer and gyroscope measurements for gesture recognition.
								</p>

								<p>
									The IMU is interfaced to the Pico W using the I<sup>2</sup>C protocol operating at
									3.3&nbsp;V logic levels. Power and signal connections are made directly between the
									Pico W and the MPU6050 breakout board.
								</p>

								<h3>Electrical Connections</h3>

								<table class="hardware-table">
									<thead>
									<tr>
										<th>MPU6050 Pin</th>
										<th>Pico W Pin</th>
										<th>Description</th>
									</tr>
									</thead>
									<tbody>
									<tr>
										<td>VCC</td>
										<td>3.3&nbsp;V</td>
										<td>Power supply for IMU (3.3&nbsp;V logic)</td>
									</tr>
									<tr>
										<td>GND</td>
										<td>GND</td>
										<td>Common electrical ground</td>
									</tr>
									<tr>
										<td>SCL</td>
										<td>GPIO&nbsp;9 (I<sup>2</sup>C SCL)</td>
										<td>I<sup>2</sup>C clock line</td>
									</tr>
									<tr>
										<td>SDA</td>
										<td>GPIO&nbsp;8 (I<sup>2</sup>C SDA)</td>
										<td>I<sup>2</sup>C data line</td>
									</tr>
									</tbody>
								</table>

								<h3>Physical Layout</h3>
								<p>
									The Pico W and MPU6050 are mounted on a solderless breadboard to allow rapid
									prototyping and iterative development. Short jumper wires are used for the
									I<sup>2</sup>C lines to minimize noise and signal integrity issues. The shared ground
									reference ensures stable sensor measurements and reliable communication.
								</p>

								<p>
									This hardware configuration allows the Pico W to continuously acquire inertial
									measurements, perform on-board sensor fusion, and transmit gesture commands
									wirelessly without the need for external processing hardware.
								</p>


								<figure style="text-align: center;">
									<img
									src="images/gesture_control.png"
									alt="Raspberry Pi Pico W connected to MPU6050 IMU on a breadboard using I2C"
									style="max-width: 70%; height: auto;"
									/>
									<figcaption>
									Figure 1: Breadboard-based gesture hardware consisting of a Raspberry Pi Pico W
									interfaced with an MPU6050 IMU over I<sup>2</sup>C.
									</figcaption>
								</figure>
							</section>

						<!-- Gesture Control Software -->
							<section id="gesturecontrolsw" class="main">
								 <h2>Gesture Control Software</h2>

									<p>
										This system implements a <strong>client-side inertial gesture interface</strong> on a Raspberry Pi Pico W.
										The Pico W acquires raw inertial measurements from an MPU6050 IMU via I2C, performs fixed-point sensor fusion
										to estimate orientation, discretizes the estimated state into gesture events, and transmits those events to a
										remote server using HTTP over Wi-Fi. The Pico W acts exclusively as a <strong>network client</strong>,
										initiating all communication.
									</p>

									<p>
										The signal path can be summarized as:
										<br />
										<code>IMU → Fixed-Point Sensor Fusion → Gesture State Machine → HTTP Client</code>
									</p>

									<hr />

									<section id="data-acquisition">
										<h2>IMU Data Acquisition Layer</h2>

										<h3>Hardware Interface and Configuration</h3>
										<p>
										The MPU6050 is interfaced over I2C using the RP2040’s hardware I2C controller. During initialization,
										the device is configured as follows:
										</p>
										<ul>
										<li>Power management disabled (device wake-up)</li>
										<li>Accelerometer full-scale range: &plusmn;2 g</li>
										<li>Gyroscope full-scale range: &plusmn;250 deg/s</li>
										<li>Sample rate divider configured for 1 kHz internal sampling</li>
										</ul>
										<p>
										All configuration writes are performed using blocking I2C transactions to ensure deterministic sensor state
										before data acquisition begins.
										</p>

										<h3>1.2 Raw Measurement Acquisition</h3>
										<p>
										Accelerometer and gyroscope data are read from the MPU6050 using register auto-increment:
										</p>
										<ul>
										<li>Accelerometer: registers <code>0x3B–0x40</code></li>
										<li>Gyroscope: registers <code>0x43–0x48</code></li>
										</ul>
										<p>
										Each axis measurement is reconstructed from two consecutive 8-bit registers into a signed 16-bit value.
										The data is then converted into <strong>Q15 fixed-point format</strong>, allowing subsequent signal processing
										to be performed without floating-point hardware and improving real-time determinism.
										</p>
										<p>
										The raw measurement vectors are represented as:
										<br />
										<code>a = [a<sub>x</sub>, a<sub>y</sub>, a<sub>z</sub>], &nbsp; ω = [ω<sub>x</sub>, ω<sub>y</sub>, ω<sub>z</sub>]</code>
										</p>
									</section>

									<hr />

									<section id="sensor-fusion">
										<h2>Sensor Fusion and Orientation Estimation</h2>

										<h3>Accelerometer-Based Tilt Estimation</h3>
										<p>
										The instantaneous tilt angle is derived from accelerometer measurements using the Y–Z plane:
										</p>
										<p>
										<code>θ<sub>acc</sub> = atan2(-a<sub>y</sub>, -a<sub>z</sub>)</code>
										</p>
										<p>
										This angle provides an absolute reference to gravity but is subject to high-frequency noise and transient linear acceleration.
										</p>

										<h3>Gyroscope Integration</h3>
										<p>
										Gyroscope data provides angular velocity around the X-axis. Incremental angular displacement is computed as:
										</p>
										<p>
										<code>Δθ<sub>gyro</sub> = ω<sub>x</sub> · Δt</code>
										</p>
										<p>
										where <code>Δt</code> is assumed constant and approximately 1 ms. This integration provides smooth short-term motion tracking
										but accumulates bias-induced drift over time.
										</p>

										<h3>Complementary Filter Implementation</h3>
										<p>
										To combine the strengths of both sensors, a <strong>first-order complementary filter</strong> is implemented in fixed-point arithmetic:
										</p>
										<p>
										<code>
											θ<sub>k</sub> = α(θ<sub>k-1</sub> − Δθ<sub>gyro</sub>) + (1 − α)θ<sub>acc</sub>
										</code>
										</p>
										<ul>
										<li><code>α = 0.999</code></li>
										<li><code>θ<sub>k</sub></code> is the filtered orientation estimate</li>
										</ul>
										<p>
										The filter effectively acts as a high-pass filter on gyroscope data and a low-pass filter on accelerometer data.
										To prevent instability and large transients, the filtered angle is saturated to:
										</p>
										<p>
										<code>θ<sub>k</sub> ∈ [−5°, +5°]</code>
										</p>
										<p>
										This filtered output (<code>complementary_angle</code>) represents the system’s internal orientation state.
										</p>
									</section>

									<hr />

									<section id="gesture-detection">
										<h2>Gesture Detection and State Quantization</h2>

										<h3>Continuous-to-Discrete State Mapping</h3>
										<p>
										Gesture detection maps the continuous orientation estimate into a discrete state:
										</p>
										<table class="gesture-table">
											<thead>
												<tr>
												<th>Condition</th>
												<th>Gesture</th>
												</tr>
											</thead>
											<tbody>
												<tr>
												<td>θ &gt; 0</td>
												<td>FORWARD</td>
												</tr>
												<tr>
												<td>θ &lt; 0</td>
												<td>BACKWARD</td>
												</tr>
												<tr>
												<td>θ = 0</td>
												<td>NONE</td>
												</tr>
											</tbody>
											</table>
										<p>
										This reduces a continuous sensor signal into a finite command alphabet suitable for network transmission and downstream control.
										</p>

										<h3>3.2 Edge-Triggered Gesture Emission</h3>
										<p>
										To prevent command flooding and oscillatory behavior, gesture transmission is edge-triggered. The system maintains the last
										transmitted gesture and emits a new command only when a state transition occurs:
										</p>
										<p><code>G<sub>k</sub> ≠ G<sub>k-1</sub></code></p>
										<p>
										This makes gesture output event-driven, improving robustness under noisy sensor conditions.
										</p>
									</section>

									<hr />

									<section id="wireless-communication">
										<h2>Wireless Communication Subsystem</h2>

										<h3>Network Role and Initialization</h3>
										<p>
										The Pico W operates in <strong>station (STA) mode</strong>, connecting to an external access point using WPA2 authentication.
										The CYW43 networking stack is initialized at startup, and all subsequent communication occurs through a single TCP/IP context.
										</p>
										<p>
										The Pico W does not listen for inbound connections and does not host a server; it functions solely as a client.
										</p>

										<h3>HTTP-Based Gesture Transport</h3>
										<p>
										Gesture events are transmitted to a remote server using synchronous HTTP GET requests. Each request encodes the gesture state
										in the URL query string:
										</p>
										<ul>
										<li><code>GET /msg?msg=FORWARD</code></li>
										<li><code>GET /msg?msg=BACKWARD</code></li>
										</ul>
										<p>
										The HTTP client blocks until a response is received or the server closes the connection. Successful transmission is inferred
										from standard HTTP client return codes. This design prioritizes simplicity and debuggability over latency and bandwidth efficiency.
										</p>
									</section>

									<hr />

									<section id="execution-model">
										<h2>Execution Model and Timing</h2>
										<p>
										The system runs in a single-threaded polling loop at approximately 10 Hz. Each loop iteration performs:
										</p>
										<ol>
										<li>Blocking I2C read of IMU data</li>
										<li>Fixed-point sensor fusion update</li>
										<li>Gesture classification</li>
										<li>Conditional HTTP request transmission</li>
										<li>Fixed delay (<code>sleep_ms(100)</code>)</li>
										</ol>
										<p>
										This sequential model ensures deterministic ordering but introduces latency bounded by the loop period and network transaction duration.
										</p>
									</section>

									<hr />

									<section id="constraints-extensions">
										<h2>Design Constraints and Extensions</h2>

										<h3>Current Constraints</h3>
										<ul>
										<li>Fixed <code>Δt</code> assumption for gyroscope integration</li>
										<li>Polling-based IMU acquisition despite interrupt configuration</li>
										<li>Binary gesture classification without hysteresis/dead zone</li>
										<li>Relatively high-latency HTTP transport</li>
										</ul>

										<h3>Potential Extensions</h3>
										<ul>
										<li>Interrupt-driven IMU sampling</li>
										<li>Adaptive complementary filter gain</li>
										<li>Hysteresis/dead-zone gesture thresholds</li>
										<li>Non-blocking or UDP-based communication</li>
										<li>Extension to multi-axis and compound gestures</li>
										</ul>
									</section>

									<hr />
							</section>														
						<!-- Results -->
							<section id="results" class="main">
								<h2>Results</h2>
								<p> <!-- BODY TEXT FOR RESULTS -->
									
								</p>
							</section>

						<!-- Conclusions -->
							<section id="conclusions" class="main">
								<h2>Conclusions</h2>
								<p> <!-- BODY TEXT FOR CONCLUSIONS -->
									
								</p>
							</section>
						<!-- Appendix -->
							<section id="appendix" class="main">
								<h2>Appendix</h2>
								<p> <!-- BODY TEXT FOR APPENDIX -->
								
								</p>

							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section>
							<h2>Aliquam sed mauris</h2>
							<p>Sed lorem ipsum dolor sit amet et nullam consequat feugiat consequat magna adipiscing tempus etiam dolore veroeros. eget dapibus mauris. Cras aliquet, nisl ut viverra sollicitudin, ligula erat egestas velit, vitae tincidunt odio.</p>
							<ul class="actions">
								<li><a href="generic.html" class="button">Learn More</a></li>
							</ul>
						</section>
						<section>
							<h2>Etiam feugiat</h2>
							<dl class="alt">
								<dt>Address</dt>
								<dd>1234 Somewhere Road &bull; Nashville, TN 00000 &bull; USA</dd>
								<dt>Phone</dt>
								<dd>(000) 000-0000 x 0000</dd>
								<dt>Email</dt>
								<dd><a href="#">information@untitled.tld</a></dd>
							</dl>
							<ul class="icons">
								<li><a href="#" class="icon brands fa-twitter alt"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands fa-facebook-f alt"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands fa-instagram alt"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands fa-dribbble alt"><span class="label">Dribbble</span></a></li>
							</ul>
						</section>
						<p class="copyright">&copy; Untitled. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>

